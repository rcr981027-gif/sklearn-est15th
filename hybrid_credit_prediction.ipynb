{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "intro",
            "metadata": {},
            "source": [
                "# [Hybrid] Rank 1 Features + Rank 3 Stacking Ensemble\n",
                "이 노트북은 1위의 우수한 특징 추출(Feature Engineering) 기법과 3위의 모델 앙상블 전략을 결합한 통합 솔루션입니다.\n",
                "\n",
                "## 핵심 포인트\n",
                "- **Rank 1 전략**: 고유 ID 생성, KMeans 클러스터링, 정교한 시간 파생 변수\n",
                "- **Rank 3 전략**: CatBoost + LGBM + XGBoost 가중치 블렌딩 앙상블"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "install",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Requirement already satisfied: catboost in c:\\users\\alsld\\miniconda3\\envs\\ds\\lib\\site-packages (1.2.8)\n",
                        "Requirement already satisfied: category_encoders in c:\\users\\alsld\\miniconda3\\envs\\ds\\lib\\site-packages (2.9.0)\n",
                        "Requirement already satisfied: lightgbm in c:\\users\\alsld\\miniconda3\\envs\\ds\\lib\\site-packages (4.6.0)\n",
                        "Requirement already satisfied: xgboost in c:\\users\\alsld\\miniconda3\\envs\\ds\\lib\\site-packages (3.1.3)\n",
                        "Requirement already satisfied: graphviz in c:\\users\\alsld\\miniconda3\\envs\\ds\\lib\\site-packages (from catboost) (0.21)\n",
                        "Requirement already satisfied: matplotlib in c:\\users\\alsld\\miniconda3\\envs\\ds\\lib\\site-packages (from catboost) (3.10.8)\n",
                        "Requirement already satisfied: numpy<3.0,>=1.16.0 in c:\\users\\alsld\\miniconda3\\envs\\ds\\lib\\site-packages (from catboost) (2.1.3)\n",
                        "Requirement already satisfied: pandas>=0.24 in c:\\users\\alsld\\miniconda3\\envs\\ds\\lib\\site-packages (from catboost) (2.3.3)\n",
                        "Requirement already satisfied: scipy in c:\\users\\alsld\\miniconda3\\envs\\ds\\lib\\site-packages (from catboost) (1.16.3)\n",
                        "Requirement already satisfied: plotly in c:\\users\\alsld\\miniconda3\\envs\\ds\\lib\\site-packages (from catboost) (6.5.2)\n",
                        "Requirement already satisfied: six in c:\\users\\alsld\\miniconda3\\envs\\ds\\lib\\site-packages (from catboost) (1.17.0)\n",
                        "Requirement already satisfied: patsy>=0.5.1 in c:\\users\\alsld\\miniconda3\\envs\\ds\\lib\\site-packages (from category_encoders) (1.0.2)\n",
                        "Requirement already satisfied: scikit-learn>=1.6.0 in c:\\users\\alsld\\miniconda3\\envs\\ds\\lib\\site-packages (from category_encoders) (1.7.2)\n",
                        "Requirement already satisfied: statsmodels>=0.9.0 in c:\\users\\alsld\\miniconda3\\envs\\ds\\lib\\site-packages (from category_encoders) (0.14.6)\n",
                        "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\alsld\\miniconda3\\envs\\ds\\lib\\site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
                        "Requirement already satisfied: pytz>=2020.1 in c:\\users\\alsld\\miniconda3\\envs\\ds\\lib\\site-packages (from pandas>=0.24->catboost) (2025.2)\n",
                        "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\alsld\\miniconda3\\envs\\ds\\lib\\site-packages (from pandas>=0.24->catboost) (2025.3)\n",
                        "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\alsld\\miniconda3\\envs\\ds\\lib\\site-packages (from scikit-learn>=1.6.0->category_encoders) (1.5.3)\n",
                        "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\alsld\\miniconda3\\envs\\ds\\lib\\site-packages (from scikit-learn>=1.6.0->category_encoders) (3.6.0)\n",
                        "Requirement already satisfied: packaging>=21.3 in c:\\users\\alsld\\miniconda3\\envs\\ds\\lib\\site-packages (from statsmodels>=0.9.0->category_encoders) (25.0)\n",
                        "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\alsld\\miniconda3\\envs\\ds\\lib\\site-packages (from matplotlib->catboost) (1.3.3)\n",
                        "Requirement already satisfied: cycler>=0.10 in c:\\users\\alsld\\miniconda3\\envs\\ds\\lib\\site-packages (from matplotlib->catboost) (0.12.1)\n",
                        "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\alsld\\miniconda3\\envs\\ds\\lib\\site-packages (from matplotlib->catboost) (4.61.1)\n",
                        "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\alsld\\miniconda3\\envs\\ds\\lib\\site-packages (from matplotlib->catboost) (1.4.9)\n",
                        "Requirement already satisfied: pillow>=8 in c:\\users\\alsld\\miniconda3\\envs\\ds\\lib\\site-packages (from matplotlib->catboost) (11.3.0)\n",
                        "Requirement already satisfied: pyparsing>=3 in c:\\users\\alsld\\miniconda3\\envs\\ds\\lib\\site-packages (from matplotlib->catboost) (3.3.1)\n",
                        "Requirement already satisfied: narwhals>=1.15.1 in c:\\users\\alsld\\miniconda3\\envs\\ds\\lib\\site-packages (from plotly->catboost) (2.15.0)\n"
                    ]
                }
            ],
            "source": [
                "!pip install catboost category_encoders lightgbm xgboost"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "imports",
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "import warnings\n",
                "import random\n",
                "from sklearn.metrics import log_loss\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from category_encoders.ordinal import OrdinalEncoder\n",
                "from sklearn.model_selection import StratifiedKFold\n",
                "from sklearn.cluster import KMeans\n",
                "from catboost import CatBoostClassifier\n",
                "import lightgbm as lgb\n",
                "from lightgbm import LGBMClassifier\n",
                "from xgboost import XGBClassifier\n",
                "\n",
                "warnings.filterwarnings(action='ignore')\n",
                "\n",
                "SEED = 42\n",
                "random.seed(SEED)\n",
                "np.random.seed(SEED)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "preprocessing",
            "metadata": {},
            "outputs": [],
            "source": [
                "def preprocess_data(train_df, test_df):\n",
                "    print(\"Preprosessing...\")\n",
                "    train_df.fillna('NaN', inplace=True)\n",
                "    test_df.fillna('NaN', inplace=True)\n",
                "    \n",
                "    # Outlier (Rank 1)\n",
                "    train_df = train_df[train_df['family_size'] <= 7].reset_index(drop=True)\n",
                "    \n",
                "    # Drop constants\n",
                "    drop_cols = ['index', 'FLAG_MOBIL']\n",
                "    train_df.drop([c for c in drop_cols if c in train_df.columns], axis=1, inplace=True)\n",
                "    test_df.drop([c for c in drop_cols if c in test_df.columns], axis=1, inplace=True)\n",
                "    \n",
                "    # Correct time features\n",
                "    train_df['DAYS_EMPLOYED'] = train_df['DAYS_EMPLOYED'].map(lambda x: 0 if x > 0 else x)\n",
                "    test_df['DAYS_EMPLOYED'] = test_df['DAYS_EMPLOYED'].map(lambda x: 0 if x > 0 else x)\n",
                "    \n",
                "    feats = ['DAYS_BIRTH', 'begin_month', 'DAYS_EMPLOYED']\n",
                "    for feat in feats:\n",
                "        train_df[feat] = np.abs(train_df[feat])\n",
                "        test_df[feat] = np.abs(test_df[feat])\n",
                "        \n",
                "    for df in [train_df, test_df]:\n",
                "        # Rank 1 Features\n",
                "        df['before_EMPLOYED'] = df['DAYS_BIRTH'] - df['DAYS_EMPLOYED']\n",
                "        df['income_total_befofeEMP_ratio'] = df['income_total'] / (df['before_EMPLOYED'] + 1)\n",
                "        \n",
                "        df['Age'] = df['DAYS_BIRTH'] // 365\n",
                "        df['EMPLOYED'] = df['DAYS_EMPLOYED'] // 365\n",
                "        \n",
                "        df['DAYS_BIRTH_m'] = np.floor(df['DAYS_BIRTH'] / 30) % 12\n",
                "        df['DAYS_BIRTH_w'] = np.floor(df['DAYS_BIRTH'] / 7) % 4\n",
                "        df['DAYS_EMPLOYED_m'] = np.floor(df['DAYS_EMPLOYED'] / 30) % 12\n",
                "        df['DAYS_EMPLOYED_w'] = np.floor(df['DAYS_EMPLOYED'] / 7) % 4\n",
                "        \n",
                "        df['ability'] = df['income_total'] / (df['DAYS_BIRTH'] + df['DAYS_EMPLOYED'] + 1)\n",
                "        df['income_mean'] = df['income_total'] / df['family_size']\n",
                "        \n",
                "        # Rank 3 Features\n",
                "        df['income_age'] = df['income_total'] * df['Age']\n",
                "        df['income_emp'] = df['income_total'] * df['EMPLOYED']\n",
                "        \n",
                "        # ID (Rank 1)\n",
                "        id_cols = ['child_num', 'income_total', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'work_phone', 'phone', 'email', 'family_size', 'gender', 'car', 'reality', 'income_type', 'edu_type', 'family_type', 'house_type', 'occyp_type']\n",
                "        df['ID'] = df[id_cols].astype(str).agg('_'.join, axis=1)\n",
                "        \n",
                "    train_df.drop(['child_num', 'DAYS_BIRTH', 'DAYS_EMPLOYED'], axis=1, inplace=True)\n",
                "    test_df.drop(['child_num', 'DAYS_BIRTH', 'DAYS_EMPLOYED'], axis=1, inplace=True)\n",
                "    \n",
                "    categorical_feats = train_df.select_dtypes(include=['object']).columns.tolist()\n",
                "    train_df['income_total'] = np.log1p(1 + train_df['income_total'])\n",
                "    test_df['income_total'] = np.log1p(1 + test_df['income_total'])\n",
                "    \n",
                "    encoder = OrdinalEncoder(cols=categorical_feats)\n",
                "    train_df[categorical_feats] = encoder.fit_transform(train_df[categorical_feats])\n",
                "    test_df[categorical_feats] = encoder.transform(test_df[categorical_feats])\n",
                "    \n",
                "    train_df['ID'] = train_df['ID'].astype('int64')\n",
                "    test_df['ID'] = test_df['ID'].astype('int64')\n",
                "    \n",
                "    print(\"Clustering...\")\n",
                "    kmeans_train = train_df.drop(['credit'], axis=1)\n",
                "    kmeans = KMeans(n_clusters=36, random_state=SEED).fit(kmeans_train)\n",
                "    train_df['cluster'] = kmeans.predict(kmeans_train)\n",
                "    test_df['cluster'] = kmeans.predict(test_df)\n",
                "    \n",
                "    numerical_feats = train_df.select_dtypes(exclude=['object', 'category']).columns.tolist()\n",
                "    if 'credit' in numerical_feats: numerical_feats.remove('credit')\n",
                "    scaler_feats = [c for c in numerical_feats if c != 'income_total']\n",
                "    scaler = StandardScaler()\n",
                "    train_df[scaler_feats] = scaler.fit_transform(train_df[scaler_feats])\n",
                "    test_df[scaler_feats] = scaler.transform(test_df[scaler_feats])\n",
                "    \n",
                "    return train_df, test_df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "run_all",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Preprosessing...\n",
                        "Clustering...\n",
                        "Fold 0...\n",
                        "Training until validation scores don't improve for 50 rounds\n",
                        "Did not meet early stopping. Best iteration is:\n",
                        "[1000]\tvalid_0's multi_logloss: 0.718165\n",
                        "Fold 1...\n",
                        "Training until validation scores don't improve for 50 rounds\n",
                        "Did not meet early stopping. Best iteration is:\n",
                        "[1000]\tvalid_0's multi_logloss: 0.733991\n",
                        "Fold 2...\n",
                        "Training until validation scores don't improve for 50 rounds\n",
                        "Did not meet early stopping. Best iteration is:\n",
                        "[1000]\tvalid_0's multi_logloss: 0.726591\n",
                        "Fold 3...\n",
                        "Training until validation scores don't improve for 50 rounds\n",
                        "Did not meet early stopping. Best iteration is:\n",
                        "[1000]\tvalid_0's multi_logloss: 0.735904\n",
                        "Fold 4...\n",
                        "Training until validation scores don't improve for 50 rounds\n",
                        "Did not meet early stopping. Best iteration is:\n",
                        "[1000]\tvalid_0's multi_logloss: 0.732314\n",
                        "Fold 5...\n",
                        "Training until validation scores don't improve for 50 rounds\n",
                        "Did not meet early stopping. Best iteration is:\n",
                        "[1000]\tvalid_0's multi_logloss: 0.730892\n",
                        "Fold 6...\n",
                        "Training until validation scores don't improve for 50 rounds\n",
                        "Did not meet early stopping. Best iteration is:\n",
                        "[1000]\tvalid_0's multi_logloss: 0.71688\n",
                        "Fold 7...\n",
                        "Training until validation scores don't improve for 50 rounds\n",
                        "Did not meet early stopping. Best iteration is:\n",
                        "[1000]\tvalid_0's multi_logloss: 0.736925\n",
                        "Fold 8...\n",
                        "Training until validation scores don't improve for 50 rounds\n",
                        "Did not meet early stopping. Best iteration is:\n",
                        "[1000]\tvalid_0's multi_logloss: 0.742318\n",
                        "Fold 9...\n",
                        "Training until validation scores don't improve for 50 rounds\n",
                        "Did not meet early stopping. Best iteration is:\n",
                        "[1000]\tvalid_0's multi_logloss: 0.734241\n",
                        "Fold 10...\n",
                        "Training until validation scores don't improve for 50 rounds\n",
                        "Did not meet early stopping. Best iteration is:\n",
                        "[1000]\tvalid_0's multi_logloss: 0.727151\n",
                        "Fold 11...\n",
                        "Training until validation scores don't improve for 50 rounds\n",
                        "Did not meet early stopping. Best iteration is:\n",
                        "[1000]\tvalid_0's multi_logloss: 0.7501\n",
                        "Fold 12...\n",
                        "Training until validation scores don't improve for 50 rounds\n",
                        "Did not meet early stopping. Best iteration is:\n",
                        "[1000]\tvalid_0's multi_logloss: 0.729553\n",
                        "Fold 13...\n",
                        "Training until validation scores don't improve for 50 rounds\n",
                        "Did not meet early stopping. Best iteration is:\n",
                        "[1000]\tvalid_0's multi_logloss: 0.734162\n",
                        "Fold 14...\n",
                        "Training until validation scores don't improve for 50 rounds\n",
                        "Did not meet early stopping. Best iteration is:\n",
                        "[1000]\tvalid_0's multi_logloss: 0.720066\n",
                        "Submission and Test files saved in 신용카드 사용자 예측/!\n"
                    ]
                }
            ],
            "source": [
                "train_df = pd.read_csv('data/train.csv')\n",
                "test_df = pd.read_csv('data/test.csv')\n",
                "train_df, test_df = preprocess_data(train_df, test_df)\n",
                "\n",
                "n_fold = 15\n",
                "skf = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=SEED)\n",
                "\n",
                "X = train_df.drop('credit', axis=1)\n",
                "y = train_df['credit']\n",
                "X_test = test_df\n",
                "\n",
                "cat_preds = np.zeros((X_test.shape[0], 3))\n",
                "lgb_preds = np.zeros((X_test.shape[0], 3))\n",
                "xgb_preds = np.zeros((X_test.shape[0], 3))\n",
                "\n",
                "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
                "    print(f\"Fold {fold}...\")\n",
                "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
                "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
                "    \n",
                "    cat = CatBoostClassifier(iterations=2000, random_state=SEED, verbose=0, early_stopping_rounds=100)\n",
                "    cat.fit(X_train, y_train, eval_set=[(X_val, y_val)])\n",
                "    cat_preds += cat.predict_proba(X_test) / n_fold\n",
                "    \n",
                "    lgbm = LGBMClassifier(n_estimators=1000, learning_rate=0.01, random_state=SEED, verbosity=-1)\n",
                "    lgbm.fit(X_train, y_train, eval_set=[(X_val, y_val)], callbacks=[lgb.early_stopping(stopping_rounds=50)])\n",
                "    lgb_preds += lgbm.predict_proba(X_test) / n_fold\n",
                "    \n",
                "    xgboost = XGBClassifier(n_estimators=1000, learning_rate=0.01, random_state=SEED, verbosity=0, early_stopping_rounds=50)\n",
                "    xgboost.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n",
                "    xgb_preds += xgboost.predict_proba(X_test) / n_fold\n",
                "\n",
                "final_preds = 0.5 * cat_preds + 0.3 * lgb_preds + 0.2 * xgb_preds\n",
                "output_dir = '신용카드 사용자 예측/'\n",
                "submission = pd.read_csv('data/sample_submission.csv')\n",
                "submission.iloc[:, 1:] = final_preds\n",
                "submission.to_csv(output_dir + 'submission.csv', index=False)\n",
                "test_df.to_csv(output_dir + 'test.csv', index=False)\n",
                "print(f\"Submission and Test files saved in {output_dir}!\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "DS",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
