{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Scikit-learn 내장 데이터셋: load_digits 분석 및 분류 모델 프로젝트\n",
                "\n",
                "이 노트북은 Scikit-learn에서 제공하는 손글씨 숫자(Digits) 데이터셋을 활용하여 데이터를 분석하고, 다양한 머신러닝 모델을 통해 숫자를 분류하는 과정을 담고 있습니다.\n",
                "\n",
                "## 데이터셋 소개: Optical Recognition of Handwritten Digits Data\n",
                "- **데이터 구성**: 총 1,797개의 샘플\n",
                "- **특성(Features)**: 8x8 픽셀 이미지 (총 64개의 각 픽셀 밝기 값, 0~16 사이의 정수)\n",
                "- **타겟(Target)**: 0부터 9까지의 숫자 (클래스 10개)\n",
                "- **목표**: 64개의 픽셀 값을 입력받아 해당 이미지가 어떤 숫자인지 예측하는 분류 모델 구축"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.datasets import load_digits\n",
                "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
                "\n",
                "# 한글 폰트 설정 (Windows 기준)\n",
                "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
                "plt.rcParams['axes.unicode_minus'] = False\n",
                "\n",
                "# 데이터 로드\n",
                "digits = load_digits()\n",
                "X = digits.data\n",
                "y = digits.target\n",
                "\n",
                "print(f\"데이터 크기: {X.shape}\")\n",
                "print(f\"타겟 클래스: {np.unique(y)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. 탐색적 데이터 분석 (EDA)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 데이터프레임 변환 후 기초 통계 확인\n",
                "df = pd.DataFrame(X, columns=[f\"pixel_{i}\" for i in range(64)])\n",
                "df['target'] = y\n",
                "\n",
                "display(df.head())\n",
                "print(df.info())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 클래스별 분포 시각화\n",
                "plt.figure(figsize=(8, 4))\n",
                "sns.countplot(x='target', data=df, palette='viridis')\n",
                "plt.title('숫자별 데이터 분포')\n",
                "plt.show()\n",
                "\n",
                "print(\"클래스별 샘플 수:\")\n",
                "print(df['target'].value_counts().sort_index())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 실제 이미지 시각화\n",
                "plt.figure(figsize=(12, 5))\n",
                "for i in range(10):\n",
                "    plt.subplot(2, 5, i + 1)\n",
                "    plt.imshow(digits.images[i], cmap='gray')\n",
                "    plt.title(f\"Label: {y[i]}\")\n",
                "    plt.axis('off')\n",
                "plt.suptitle('Digits 데이터셋 실제 이미지 예시', fontsize=16)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. 데이터 전처리 및 특성 엔지니어링"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 학습 데이터와 테스트 데이터 분리\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
                "\n",
                "# 데이터 스케일링 (픽셀값 0~16을 표준화)\n",
                "scaler = StandardScaler()\n",
                "X_train_scaled = scaler.fit_transform(X_train)\n",
                "X_test_scaled = scaler.transform(X_test)\n",
                "\n",
                "print(f\"학습 데이터 크기: {X_train.shape}\")\n",
                "print(f\"테스트 데이터 크기: {X_test.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. 모델링 (6가지 기초 모델 사용)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
                "from sklearn.svm import SVC\n",
                "from sklearn.neighbors import KNeighborsClassifier\n",
                "from sklearn.tree import DecisionTreeClassifier\n",
                "\n",
                "# 모델 정의\n",
                "models = {\n",
                "    'LogisticRegression': LogisticRegression(max_iter=10000, random_state=42),\n",
                "    'RandomForest': RandomForestClassifier(random_state=42),\n",
                "    'SVM': SVC(random_state=42, probability=True),\n",
                "    'KNN': KNeighborsClassifier(),\n",
                "    'DecisionTree': DecisionTreeClassifier(random_state=42),\n",
                "    'GradientBoosting': GradientBoostingClassifier(random_state=42)\n",
                "}\n",
                "\n",
                "# 교차 검증을 통한 성능 비교\n",
                "results = {}\n",
                "for name, model in models.items():\n",
                "    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5)\n",
                "    results[name] = cv_scores.mean()\n",
                "    print(f\"{name} CV Accuracy: {cv_scores.mean():.4f}\")\n",
                "\n",
                "# 성능 기준 내림차순 정렬\n",
                "sorted_results = sorted(results.items(), key=lambda x: x[1], reverse=True)\n",
                "print(\"\\n--- 모델 성능 순위 ---\")\n",
                "for i, (name, score) in enumerate(sorted_results):\n",
                "    print(f\"{i+1}. {name}: {score:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. 하이퍼 파라미터 튜닝 및 성능 상위 4개 모델 선정"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 상위 4개 모델 선정\n",
                "top_4_model_names = [name for name, score in sorted_results[:4]]\n",
                "print(f\"선정된 상위 4개 모델: {top_4_model_names}\")\n",
                "\n",
                "best_estimators = {}\n",
                "\n",
                "# SVM 튜닝\n",
                "if 'SVM' in top_4_model_names:\n",
                "    param_svm = {'C': [0.1, 1, 10], 'gamma': ['scale', 'auto', 0.1, 0.01]}\n",
                "    grid_svm = GridSearchCV(SVC(probability=True, random_state=42), param_svm, cv=3)\n",
                "    grid_svm.fit(X_train_scaled, y_train)\n",
                "    best_estimators['SVM'] = grid_svm.best_estimator_\n",
                "\n",
                "# RandomForest 튜닝\n",
                "if 'RandomForest' in top_4_model_names:\n",
                "    param_rf = {'n_estimators': [100, 200], 'max_depth': [None, 10, 20]}\n",
                "    grid_rf = GridSearchCV(RandomForestClassifier(random_state=42), param_rf, cv=3)\n",
                "    grid_rf.fit(X_train_scaled, y_train)\n",
                "    best_estimators['RandomForest'] = grid_rf.best_estimator_\n",
                "\n",
                "# KNN 튜닝\n",
                "if 'KNN' in top_4_model_names:\n",
                "    param_knn = {'n_neighbors': [3, 5, 7, 9], 'weights': ['uniform', 'distance']}\n",
                "    grid_knn = GridSearchCV(KNeighborsClassifier(), param_knn, cv=3)\n",
                "    grid_knn.fit(X_train_scaled, y_train)\n",
                "    best_estimators['KNN'] = grid_knn.best_estimator_\n",
                "\n",
                "# LogisticRegression 튜닝\n",
                "if 'LogisticRegression' in top_4_model_names:\n",
                "    param_lr = {'C': [0.1, 1, 10]}\n",
                "    grid_lr = GridSearchCV(LogisticRegression(max_iter=10000, random_state=42), param_lr, cv=3)\n",
                "    grid_lr.fit(X_train_scaled, y_train)\n",
                "    best_estimators['LogisticRegression'] = grid_lr.best_estimator_\n",
                "\n",
                "# GradientBoosting 튜닝 (필요한 경우)\n",
                "if 'GradientBoosting' in top_4_model_names:\n",
                "    param_gb = {'n_estimators': [50, 100], 'learning_rate': [0.05, 0.1]}\n",
                "    grid_gb = GridSearchCV(GradientBoostingClassifier(random_state=42), param_gb, cv=3)\n",
                "    grid_gb.fit(X_train_scaled, y_train)\n",
                "    best_estimators['GradientBoosting'] = grid_gb.best_estimator_\n",
                "\n",
                "print(\"튜닝 완료!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. 앙상블 모델 구축 (Soft Voting)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.ensemble import VotingClassifier\n",
                "\n",
                "# 튜닝된 상위 4개 모델로 앙상블 구성\n",
                "estimators = [(name, clf) for name, clf in best_estimators.items()]\n",
                "voting_clf = VotingClassifier(estimators=estimators, voting='soft')\n",
                "\n",
                "# 앙상블 모델 학습\n",
                "voting_clf.fit(X_train_scaled, y_train)\n",
                "\n",
                "print(f\"앙상블 포함 모델: {[name for name, _ in estimators]}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. 최종 모델 평가"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 테스트 데이터에 대해 예측\n",
                "y_pred = voting_clf.predict(X_test_scaled)\n",
                "\n",
                "print(\"--- 최종 앙상블 모델 평가 ---\")\n",
                "print(f\"Accuracy Score: {accuracy_score(y_test, y_pred):.4f}\")\n",
                "print(\"\\nClassification Report:\")\n",
                "print(classification_report(y_test, y_pred))\n",
                "\n",
                "# 혼동 행렬 시각화\n",
                "plt.figure(figsize=(10, 8))\n",
                "cm = confusion_matrix(y_test, y_pred)\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
                "plt.xlabel('Predicted')\n",
                "plt.ylabel('Actual')\n",
                "plt.title('Confusion Matrix - Ensemble Model')\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}