{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-learn Wine Dataset Classification\n",
    "## 와인 품종 분류 분석\n",
    "\n",
    "### 데이터셋 소개\n",
    "- **출처**: UCI Machine Learning Repository (scikit-learn 내장)\n",
    "- **샘플 수**: 178개\n",
    "- **특성 수**: 13개 (화학적 분석 결과)\n",
    "- **클래스 수**: 3개 (이탈리아 동일 지역의 3가지 와인 품종)\n",
    "- **용도**: 다중 클래스 분류 (Multi-class Classification)\n",
    "\n",
    "### 학습 목표\n",
    "1. 탐색적 데이터 분석 (EDA)\n",
    "2. 데이터 전처리 및 특성 스케일링\n",
    "3. 다양한 분류 모델 학습\n",
    "4. 모델 성능 평가 및 비교\n",
    "5. 최적 모델 선정 및 하이퍼파라미터 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. 라이브러리 임포트 및 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 라이브러리\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 시각화 설정\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# scikit-learn\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# 분류 모델\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# 평가 지표\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix, ConfusionMatrixDisplay,\n",
    "    roc_curve, auc, RocCurveDisplay\n",
    ")\n",
    "\n",
    "print(\"라이브러리 임포트 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "wine = load_wine()\n",
    "\n",
    "# DataFrame 생성\n",
    "df = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
    "df['target'] = wine.target\n",
    "df['target_name'] = df['target'].map({0: 'class_0', 1: 'class_1', 2: 'class_2'})\n",
    "\n",
    "print(\"데이터셋 정보:\")\n",
    "print(f\"  - 샘플 수: {len(df)}\")\n",
    "print(f\"  - 특성 수: {len(wine.feature_names)}\")\n",
    "print(f\"  - 클래스: {wine.target_names}\")\n",
    "print(f\"\\n특성 목록:\")\n",
    "for i, name in enumerate(wine.feature_names, 1):\n",
    "    print(f\"  {i:2d}. {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 미리보기\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. 탐색적 데이터 분석 (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 기본 정보 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 타입 및 결측치\n",
    "print(\"데이터 정보:\")\n",
    "print(\"=\" * 50)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기술 통계량\n",
    "df.describe().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 확인\n",
    "print(\"결측치 개수:\")\n",
    "print(df.isnull().sum())\n",
    "print(f\"\\n전체 결측치: {df.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 타겟 변수 분포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스 분포\n",
    "print(\"클래스 분포:\")\n",
    "class_counts = df['target'].value_counts().sort_index()\n",
    "for idx, count in class_counts.items():\n",
    "    print(f\"  Class {idx} ({wine.target_names[idx]}): {count} ({count/len(df)*100:.1f}%)\")\n",
    "\n",
    "# 시각화\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# 막대 그래프\n",
    "colors = ['#e74c3c', '#3498db', '#2ecc71']\n",
    "bars = axes[0].bar(wine.target_names, class_counts.values, color=colors, edgecolor='black', alpha=0.8)\n",
    "axes[0].set_xlabel('Wine Class')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Class Distribution', fontweight='bold')\n",
    "for bar, count in zip(bars, class_counts.values):\n",
    "    axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n",
    "                 str(count), ha='center', fontsize=12, fontweight='bold')\n",
    "\n",
    "# 파이 차트\n",
    "axes[1].pie(class_counts.values, labels=wine.target_names, autopct='%1.1f%%',\n",
    "            colors=colors, explode=(0.02, 0.02, 0.02), shadow=True, startangle=90)\n",
    "axes[1].set_title('Class Proportion', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 특성 분포 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 특성의 분포 (히스토그램)\n",
    "fig, axes = plt.subplots(4, 4, figsize=(16, 14))\n",
    "axes = axes.flatten()\n",
    "\n",
    "features = wine.feature_names\n",
    "for idx, col in enumerate(features):\n",
    "    for class_idx in range(3):\n",
    "        data = df[df['target'] == class_idx][col]\n",
    "        axes[idx].hist(data, bins=15, alpha=0.6, label=wine.target_names[class_idx], \n",
    "                       color=colors[class_idx], edgecolor='black')\n",
    "    axes[idx].set_title(col, fontsize=10)\n",
    "    axes[idx].legend(fontsize=8)\n",
    "\n",
    "# 빈 subplot 숨기기\n",
    "for idx in range(len(features), len(axes)):\n",
    "    axes[idx].set_visible(False)\n",
    "\n",
    "plt.suptitle('Feature Distributions by Class', y=1.02, fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 박스플롯으로 클래스별 특성 비교\n",
    "fig, axes = plt.subplots(4, 4, figsize=(16, 14))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(features):\n",
    "    sns.boxplot(data=df, x='target', y=col, ax=axes[idx], palette=colors)\n",
    "    axes[idx].set_title(col, fontsize=10)\n",
    "    axes[idx].set_xlabel('')\n",
    "    axes[idx].set_xticklabels(wine.target_names)\n",
    "\n",
    "for idx in range(len(features), len(axes)):\n",
    "    axes[idx].set_visible(False)\n",
    "\n",
    "plt.suptitle('Feature Boxplots by Class', y=1.02, fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 상관관계 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상관관계 히트맵\n",
    "plt.figure(figsize=(14, 12))\n",
    "correlation_matrix = df[features].corr()\n",
    "\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "sns.heatmap(correlation_matrix, mask=mask, annot=True, fmt='.2f',\n",
    "            cmap='RdBu_r', center=0, square=True, linewidths=0.5,\n",
    "            cbar_kws={'shrink': 0.8}, annot_kws={'size': 8})\n",
    "plt.title('Feature Correlation Heatmap', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타겟과의 상관관계\n",
    "target_corr = df[features + ['target']].corr()['target'].drop('target').sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors_bar = ['#e74c3c' if x > 0 else '#3498db' for x in target_corr.values]\n",
    "bars = plt.barh(target_corr.index, target_corr.values, color=colors_bar, edgecolor='black', alpha=0.8)\n",
    "plt.xlabel('Correlation with Target')\n",
    "plt.title('Feature Correlation with Wine Class', fontsize=14, fontweight='bold')\n",
    "plt.axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
    "\n",
    "for bar, val in zip(bars, target_corr.values):\n",
    "    plt.text(val + 0.02 if val > 0 else val - 0.08, bar.get_y() + bar.get_height()/2,\n",
    "             f'{val:.3f}', va='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 PCA를 통한 데이터 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA로 2D 시각화\n",
    "X_features = df[features].values\n",
    "y_target = df['target'].values\n",
    "\n",
    "# 스케일링 후 PCA\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_features)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "print(f\"PCA 설명된 분산 비율:\")\n",
    "print(f\"  PC1: {pca.explained_variance_ratio_[0]*100:.2f}%\")\n",
    "print(f\"  PC2: {pca.explained_variance_ratio_[1]*100:.2f}%\")\n",
    "print(f\"  Total: {sum(pca.explained_variance_ratio_)*100:.2f}%\")\n",
    "\n",
    "# 시각화\n",
    "plt.figure(figsize=(10, 8))\n",
    "for class_idx in range(3):\n",
    "    mask = y_target == class_idx\n",
    "    plt.scatter(X_pca[mask, 0], X_pca[mask, 1], c=colors[class_idx], \n",
    "                label=wine.target_names[class_idx], alpha=0.7, s=80, edgecolors='black')\n",
    "\n",
    "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}%)', fontsize=12)\n",
    "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}%)', fontsize=12)\n",
    "plt.title('PCA - Wine Classes Visualization', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성과 타겟 분리\n",
    "X = df[features]\n",
    "y = df['target']\n",
    "\n",
    "print(f\"특성 shape: {X.shape}\")\n",
    "print(f\"타겟 shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분할 (Train: 80%, Test: 20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Train 크기: {X_train.shape[0]} ({X_train.shape[0]/len(X)*100:.0f}%)\")\n",
    "print(f\"Test 크기: {X_test.shape[0]} ({X_test.shape[0]/len(X)*100:.0f}%)\")\n",
    "print(f\"\\nTrain 클래스 분포:\")\n",
    "print(y_train.value_counts().sort_index())\n",
    "print(f\"\\nTest 클래스 분포:\")\n",
    "print(y_test.value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"StandardScaler 적용 완료!\")\n",
    "print(f\"\\n스케일링 전 (Train):\")\n",
    "print(f\"  Mean: {X_train.mean().mean():.4f}\")\n",
    "print(f\"  Std: {X_train.std().mean():.4f}\")\n",
    "print(f\"\\n스케일링 후 (Train):\")\n",
    "print(f\"  Mean: {X_train_scaled.mean():.4f}\")\n",
    "print(f\"  Std: {X_train_scaled.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. 분류 모델 학습 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분류 모델 정의\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42, max_depth=5),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'AdaBoost': AdaBoostClassifier(n_estimators=100, random_state=42, algorithm='SAMME'),\n",
    "    'SVM (RBF)': SVC(kernel='rbf', probability=True, random_state=42),\n",
    "    'Naive Bayes': GaussianNB()\n",
    "}\n",
    "\n",
    "print(f\"총 {len(models)}개의 분류 모델을 학습합니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습 및 평가\n",
    "results = []\n",
    "trained_models = {}\n",
    "\n",
    "print(\"모델 학습 및 평가 진행 중...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for name, model in models.items():\n",
    "    # 스케일링이 필요한 모델 구분\n",
    "    if name in ['Logistic Regression', 'K-Nearest Neighbors', 'SVM (RBF)']:\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        y_pred_proba = model.predict_proba(X_test_scaled)\n",
    "        # Cross-validation\n",
    "        cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_proba = model.predict_proba(X_test)\n",
    "        cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    \n",
    "    # 학습된 모델 저장\n",
    "    trained_models[name] = model\n",
    "    \n",
    "    # 평가 지표 계산\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    cv_mean = cv_scores.mean()\n",
    "    cv_std = cv_scores.std()\n",
    "    \n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'CV Mean': cv_mean,\n",
    "        'CV Std': cv_std\n",
    "    })\n",
    "    \n",
    "    print(f\"{name:22s} | Acc: {accuracy:.4f} | F1: {f1:.4f} | CV: {cv_mean:.4f} (+/- {cv_std:.4f})\")\n",
    "\n",
    "# 결과 데이터프레임\n",
    "results_df = pd.DataFrame(results).sort_values('Accuracy', ascending=False)\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"모델 성능 순위 (Accuracy 기준):\")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 성능 비교 시각화\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "metrics = ['Accuracy', 'F1-Score', 'Precision', 'Recall']\n",
    "color_palette = plt.cm.RdYlGn(np.linspace(0.2, 0.8, len(results_df)))\n",
    "\n",
    "for idx, metric in enumerate(metrics):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    sorted_df = results_df.sort_values(metric, ascending=True)\n",
    "    bars = ax.barh(sorted_df['Model'], sorted_df[metric], color=color_palette, edgecolor='black')\n",
    "    ax.set_xlabel(metric)\n",
    "    ax.set_title(f'{metric} Comparison', fontweight='bold')\n",
    "    ax.set_xlim(0.8, 1.02)\n",
    "    \n",
    "    # 값 표시\n",
    "    for bar, val in zip(bars, sorted_df[metric]):\n",
    "        ax.text(val + 0.005, bar.get_y() + bar.get_height()/2, \n",
    "                f'{val:.3f}', va='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-Validation 결과 비교\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "cv_sorted = results_df.sort_values('CV Mean', ascending=True)\n",
    "colors_cv = plt.cm.RdYlGn(np.linspace(0.2, 0.8, len(cv_sorted)))\n",
    "\n",
    "bars = plt.barh(cv_sorted['Model'], cv_sorted['CV Mean'], \n",
    "                xerr=cv_sorted['CV Std'], color=colors_cv, edgecolor='black',\n",
    "                capsize=5, error_kw={'linewidth': 2})\n",
    "plt.xlabel('Cross-Validation Accuracy')\n",
    "plt.title('5-Fold Cross-Validation Results', fontsize=14, fontweight='bold')\n",
    "plt.xlim(0.85, 1.02)\n",
    "\n",
    "for bar, mean, std in zip(bars, cv_sorted['CV Mean'], cv_sorted['CV Std']):\n",
    "    plt.text(mean + std + 0.01, bar.get_y() + bar.get_height()/2,\n",
    "             f'{mean:.3f}', va='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. 상세 모델 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상위 4개 모델의 Confusion Matrix\n",
    "top_models = results_df.head(4)['Model'].tolist()\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, name in enumerate(top_models):\n",
    "    model = trained_models[name]\n",
    "    \n",
    "    if name in ['Logistic Regression', 'K-Nearest Neighbors', 'SVM (RBF)']:\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "    else:\n",
    "        y_pred = model.predict(X_test)\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(cm, display_labels=wine.target_names)\n",
    "    disp.plot(ax=axes[idx], cmap='Blues', colorbar=False)\n",
    "    axes[idx].set_title(f'{name}', fontweight='bold')\n",
    "\n",
    "plt.suptitle('Confusion Matrices - Top 4 Models', y=1.02, fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Classification Report (Best Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Model의 상세 리포트\n",
    "best_model_name = results_df.iloc[0]['Model']\n",
    "best_model = trained_models[best_model_name]\n",
    "\n",
    "if best_model_name in ['Logistic Regression', 'K-Nearest Neighbors', 'SVM (RBF)']:\n",
    "    y_pred_best = best_model.predict(X_test_scaled)\n",
    "else:\n",
    "    y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "print(f\"Best Model: {best_model_name}\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_best, target_names=wine.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Feature Importance (Tree-based Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance 비교 (Tree-based 모델)\n",
    "tree_models = ['Random Forest', 'Gradient Boosting', 'Decision Tree', 'AdaBoost']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, name in enumerate(tree_models):\n",
    "    model = trained_models[name]\n",
    "    importance = pd.DataFrame({\n",
    "        'Feature': features,\n",
    "        'Importance': model.feature_importances_\n",
    "    }).sort_values('Importance', ascending=True)\n",
    "    \n",
    "    colors_fi = plt.cm.RdYlGn(np.linspace(0.2, 0.8, len(importance)))\n",
    "    axes[idx].barh(importance['Feature'], importance['Importance'], \n",
    "                   color=colors_fi, edgecolor='black', alpha=0.8)\n",
    "    axes[idx].set_xlabel('Importance')\n",
    "    axes[idx].set_title(f'{name} - Feature Importance', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. 하이퍼파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest 하이퍼파라미터 튜닝\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7, 10, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "grid_search_rf = GridSearchCV(\n",
    "    rf, param_grid_rf, cv=5, scoring='accuracy', n_jobs=-1, verbose=1\n",
    ")\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\nBest Parameters: {grid_search_rf.best_params_}\")\n",
    "print(f\"Best CV Score: {grid_search_rf.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM 하이퍼파라미터 튜닝\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto', 0.1, 0.01],\n",
    "    'kernel': ['rbf', 'poly']\n",
    "}\n",
    "\n",
    "svm = SVC(probability=True, random_state=42)\n",
    "grid_search_svm = GridSearchCV(\n",
    "    svm, param_grid_svm, cv=5, scoring='accuracy', n_jobs=-1, verbose=1\n",
    ")\n",
    "grid_search_svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"\\nBest Parameters: {grid_search_svm.best_params_}\")\n",
    "print(f\"Best CV Score: {grid_search_svm.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 튜닝된 모델 최종 평가\n",
    "print(\"튜닝된 모델 최종 평가\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Random Forest\n",
    "best_rf = grid_search_rf.best_estimator_\n",
    "y_pred_rf = best_rf.predict(X_test)\n",
    "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "f1_rf = f1_score(y_test, y_pred_rf, average='weighted')\n",
    "print(f\"\\nTuned Random Forest:\")\n",
    "print(f\"  Accuracy: {acc_rf:.4f}\")\n",
    "print(f\"  F1-Score: {f1_rf:.4f}\")\n",
    "\n",
    "# SVM\n",
    "best_svm = grid_search_svm.best_estimator_\n",
    "y_pred_svm = best_svm.predict(X_test_scaled)\n",
    "acc_svm = accuracy_score(y_test, y_pred_svm)\n",
    "f1_svm = f1_score(y_test, y_pred_svm, average='weighted')\n",
    "print(f\"\\nTuned SVM:\")\n",
    "print(f\"  Accuracy: {acc_svm:.4f}\")\n",
    "print(f\"  F1-Score: {f1_svm:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 튜닝된 모델 Confusion Matrix\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Random Forest\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "disp_rf = ConfusionMatrixDisplay(cm_rf, display_labels=wine.target_names)\n",
    "disp_rf.plot(ax=axes[0], cmap='Blues', colorbar=False)\n",
    "axes[0].set_title(f'Tuned Random Forest (Acc: {acc_rf:.3f})', fontweight='bold')\n",
    "\n",
    "# SVM\n",
    "cm_svm = confusion_matrix(y_test, y_pred_svm)\n",
    "disp_svm = ConfusionMatrixDisplay(cm_svm, display_labels=wine.target_names)\n",
    "disp_svm.plot(ax=axes[1], cmap='Greens', colorbar=False)\n",
    "axes[1].set_title(f'Tuned SVM (Acc: {acc_svm:.3f})', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. 최종 결과 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"           Scikit-learn Wine Classification - 최종 결과\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\n[1] 데이터 개요\")\n",
    "print(f\"    - 전체 샘플 수: {len(df)}\")\n",
    "print(f\"    - 특성 수: {len(features)}\")\n",
    "print(f\"    - 클래스 수: 3 ({', '.join(wine.target_names)})\")\n",
    "print(f\"    - Train/Test: {len(X_train)}/{len(X_test)}\")\n",
    "\n",
    "print(\"\\n[2] 기본 모델 성능 (Top 3)\")\n",
    "for idx, row in results_df.head(3).iterrows():\n",
    "    print(f\"    {results_df.head(3).index.tolist().index(idx)+1}. {row['Model']}: Acc={row['Accuracy']:.4f}, F1={row['F1-Score']:.4f}\")\n",
    "\n",
    "print(\"\\n[3] 튜닝된 모델 성능\")\n",
    "print(f\"    - Random Forest: Acc={acc_rf:.4f}, F1={f1_rf:.4f}\")\n",
    "print(f\"    - SVM (RBF): Acc={acc_svm:.4f}, F1={f1_svm:.4f}\")\n",
    "\n",
    "print(\"\\n[4] 주요 특성 (Random Forest 기준)\")\n",
    "top_features_rf = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': best_rf.feature_importances_\n",
    "}).sort_values('Importance', ascending=False).head(5)\n",
    "for i, (_, row) in enumerate(top_features_rf.iterrows(), 1):\n",
    "    print(f\"    {i}. {row['Feature']}: {row['Importance']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 비교 시각화\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# 모든 모델 Accuracy 비교\n",
    "models_sorted = results_df.sort_values('Accuracy', ascending=True)\n",
    "colors_all = plt.cm.RdYlGn(np.linspace(0.2, 0.8, len(models_sorted)))\n",
    "axes[0].barh(models_sorted['Model'], models_sorted['Accuracy'], \n",
    "             color=colors_all, edgecolor='black', alpha=0.8)\n",
    "axes[0].set_xlabel('Accuracy')\n",
    "axes[0].set_title('All Models - Accuracy Comparison', fontweight='bold')\n",
    "axes[0].set_xlim(0.9, 1.01)\n",
    "axes[0].axvline(x=max(acc_rf, acc_svm), color='red', linestyle='--', \n",
    "                label=f'Tuned Best: {max(acc_rf, acc_svm):.3f}')\n",
    "axes[0].legend()\n",
    "\n",
    "# Feature Importance (Best Tuned Random Forest)\n",
    "importance_final = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': best_rf.feature_importances_\n",
    "}).sort_values('Importance', ascending=True)\n",
    "\n",
    "colors_fi = plt.cm.RdYlGn(np.linspace(0.2, 0.8, len(importance_final)))\n",
    "axes[1].barh(importance_final['Feature'], importance_final['Importance'],\n",
    "             color=colors_fi, edgecolor='black', alpha=0.8)\n",
    "axes[1].set_xlabel('Importance')\n",
    "axes[1].set_title('Tuned Random Forest - Feature Importance', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. 결론\n",
    "\n",
    "### 주요 발견사항\n",
    "\n",
    "1. **데이터 특성**\n",
    "   - 178개 샘플, 13개 특성, 3개 클래스\n",
    "   - 클래스 분포가 비교적 균형적\n",
    "   - PCA 결과 2개 주성분으로 약 55% 분산 설명\n",
    "\n",
    "2. **모델 성능**\n",
    "   - 대부분의 모델이 90% 이상의 높은 정확도 달성\n",
    "   - 앙상블 모델(Random Forest, Gradient Boosting)이 우수한 성능\n",
    "   - SVM도 스케일링 후 높은 성능 발휘\n",
    "\n",
    "3. **중요 특성**\n",
    "   - `proline`, `flavanoids`, `color_intensity`가 분류에 중요\n",
    "   - `alcohol`, `od280/od315_of_diluted_wines`도 유의미한 기여\n",
    "\n",
    "4. **하이퍼파라미터 튜닝**\n",
    "   - GridSearchCV를 통한 최적화로 성능 향상\n",
    "   - 튜닝된 Random Forest와 SVM 모두 우수한 일반화 성능\n",
    "\n",
    "### 권장 사항\n",
    "- 프로덕션 환경에서는 Random Forest 또는 SVM 권장\n",
    "- 해석 가능성이 중요한 경우 Decision Tree 또는 Logistic Regression 고려"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
