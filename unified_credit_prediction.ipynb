{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# [Combined] Credit Card Default Prediction AI\n",
                "\n",
                "This notebook combines the best strategies from the Private 1st place and Private 3rd place solutions:\n",
                "1. **Private 1st place (0.6581)**: Powerful `ID` feature identification, KMeans clustering, and 15-fold Stratified CatBoost.\n",
                "2. **Private 3rd place (0.65913)**: Feature interactions like Income-Age and Income-Employed ratios.\n",
                "\n",
                "## Key features of this version:\n",
                "- **Outlier removal**: family_size > 7\n",
                "- **Feature Engineering**: Rich `ID` concat string, `ability`, `income_mean`, and interaction terms.\n",
                "- **Clustering**: 36 segments using KMeans.\n",
                "- **Model**: CatBoost with 15-fold cross-validation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "import warnings, random\n",
                "from sklearn.metrics import log_loss\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "# from category_encoders.ordinal import OrdinalEncoder\n",
                "from sklearn.model_selection import StratifiedKFold\n",
                "from sklearn.cluster import KMeans\n",
                "from catboost import CatBoostClassifier, Pool\n",
                "\n",
                "warnings.filterwarnings(action='ignore')\n",
                "\n",
                "# Seed for reproducibility\n",
                "seed = 42\n",
                "random.seed(seed)\n",
                "np.random.seed(seed)\n",
                "\n",
                "# 1. Load Data\n",
                "import os\n",
                "base_path = r'c:\\Users\\alsld\\github\\data science\\pandas\\신용카드 사용자 예측'\n",
                "train = pd.read_csv(os.path.join(base_path, 'train.csv'))\n",
                "test = pd.read_csv(os.path.join(base_path, 'test.csv'))\n",
                "submission = pd.read_csv(os.path.join(base_path, 'sample_submission.csv'))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. Data Preprocessing\n",
                "train.fillna('NaN', inplace=True)\n",
                "test.fillna('NaN', inplace=True)\n",
                "\n",
                "# Outlier Removal\n",
                "train = train[train['family_size'] <= 7].reset_index(drop=True)\n",
                "\n",
                "# Remove constant/redundant columns\n",
                "train.drop(['index', 'FLAG_MOBIL'], axis=1, inplace=True)\n",
                "test.drop(['index', 'FLAG_MOBIL'], axis=1, inplace=True)\n",
                "\n",
                "# Normalize time features\n",
                "train['DAYS_EMPLOYED'] = train['DAYS_EMPLOYED'].map(lambda x: 0 if x > 0 else x)\n",
                "test['DAYS_EMPLOYED'] = test['DAYS_EMPLOYED'].map(lambda x: 0 if x > 0 else x)\n",
                "\n",
                "feats = ['DAYS_BIRTH', 'begin_month', 'DAYS_EMPLOYED']\n",
                "for feat in feats:\n",
                "    train[feat] = np.abs(train[feat])\n",
                "    test[feat] = np.abs(test[feat])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3. Feature Engineering\n",
                "for df in [train, test]:\n",
                "    # Professional & Personal ratios (Notebook 1)\n",
                "    df['before_EMPLOYED'] = df['DAYS_BIRTH'] - df['DAYS_EMPLOYED']\n",
                "    df['income_total_befofeEMP_ratio'] = df['income_total'] / (df['before_EMPLOYED'] + 1)\n",
                "    \n",
                "    df['Age'] = df['DAYS_BIRTH'] // 365\n",
                "    df['EMPLOYED'] = df['DAYS_EMPLOYED'] // 365\n",
                "    df['ability'] = df['income_total'] / (df['DAYS_BIRTH'] + df['DAYS_EMPLOYED'] + 1)\n",
                "    df['income_mean'] = df['income_total'] / df['family_size']\n",
                "    \n",
                "    # Time cycles (Notebook 1)\n",
                "    df['before_EMPLOYED_m'] = np.floor(df['before_EMPLOYED'] / 30) % 12\n",
                "    df['before_EMPLOYED_w'] = np.floor(df['before_EMPLOYED'] / 7) % 4\n",
                "    df['DAYS_BIRTH_m'] = np.floor(df['DAYS_BIRTH'] / 30) % 12\n",
                "    df['DAYS_BIRTH_w'] = np.floor(df['DAYS_BIRTH'] / 7) % 4\n",
                "    df['DAYS_EMPLOYED_m'] = np.floor(df['DAYS_EMPLOYED'] / 30) % 12\n",
                "    df['DAYS_EMPLOYED_w'] = np.floor(df['DAYS_EMPLOYED'] / 7) % 4\n",
                "    \n",
                "    # Interactions (Notebook 2)\n",
                "    df['income_age'] = df['income_total'] * df['Age']\n",
                "    df['income_emp'] = df['income_total'] * df['EMPLOYED']\n",
                "    \n",
                "    # ID Generation (Notebook 1)\n",
                "    df['ID'] = \\\n",
                "    df['child_num'].astype(str) + '_' + df['income_total'].astype(str) + '_' + \\\n",
                "    df['DAYS_BIRTH'].astype(str) + '_' + df['DAYS_EMPLOYED'].astype(str) + '_' + \\\n",
                "    df['work_phone'].astype(str) + '_' + df['phone'].astype(str) + '_' + \\\n",
                "    df['email'].astype(str) + '_' + df['family_size'].astype(str) + '_' + \\\n",
                "    df['gender'].astype(str) + '_' + df['car'].astype(str) + '_' + \\\n",
                "    df['reality'].astype(str) + '_' + df['income_type'].astype(str) + '_' + \\\n",
                "    df['edu_type'].astype(str) + '_' + df['family_type'].astype(str) + '_' + \\\n",
                "    df['house_type'].astype(str) + '_' + df['occyp_type'].astype(str)\n",
                "\n",
                "# Drop original columns that are summarized in others\n",
                "cols_to_drop = ['child_num', 'DAYS_BIRTH', 'DAYS_EMPLOYED']\n",
                "train.drop(cols_to_drop, axis=1, inplace=True)\n",
                "test.drop(cols_to_drop, axis=1, inplace=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "ename": "ValueError",
                    "evalue": "could not convert string to float: 'F'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
                        "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_15488\\3532920714.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# test['ID'] = test['ID'].astype('int64')\u001b[39;00m\n\u001b[32m     15\u001b[39m \n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Clustering\u001b[39;00m\n\u001b[32m     17\u001b[39m kmeans_train = train.drop([\u001b[33m'credit'\u001b[39m], axis=\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m kmeans = KMeans(n_clusters=\u001b[32m36\u001b[39m, random_state=seed).fit(kmeans_train)\n\u001b[32m     19\u001b[39m train[\u001b[33m'cluster'\u001b[39m] = kmeans.predict(kmeans_train)\n\u001b[32m     20\u001b[39m test[\u001b[33m'cluster'\u001b[39m] = kmeans.predict(test)\n\u001b[32m     21\u001b[39m \n",
                        "\u001b[32mc:\\Users\\alsld\\miniconda3\\envs\\DS\\Lib\\site-packages\\sklearn\\base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1361\u001b[39m                 skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m                     prefer_skip_nested_validation \u001b[38;5;28;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m                 )\n\u001b[32m   1364\u001b[39m             ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, *args, **kwargs)\n",
                        "\u001b[32mc:\\Users\\alsld\\miniconda3\\envs\\DS\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m   1450\u001b[39m         -------\n\u001b[32m   1451\u001b[39m         self : object\n\u001b[32m   1452\u001b[39m             Fitted estimator.\n\u001b[32m   1453\u001b[39m         \"\"\"\n\u001b[32m-> \u001b[39m\u001b[32m1454\u001b[39m         X = validate_data(\n\u001b[32m   1455\u001b[39m             self,\n\u001b[32m   1456\u001b[39m             X,\n\u001b[32m   1457\u001b[39m             accept_sparse=\u001b[33m\"csr\"\u001b[39m,\n",
                        "\u001b[32mc:\\Users\\alsld\\miniconda3\\envs\\DS\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2950\u001b[39m             out = y\n\u001b[32m   2951\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2952\u001b[39m             out = X, y\n\u001b[32m   2953\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m no_val_X \u001b[38;5;28;01mand\u001b[39;00m no_val_y:\n\u001b[32m-> \u001b[39m\u001b[32m2954\u001b[39m         out = check_array(X, input_name=\u001b[33m\"X\"\u001b[39m, **check_params)\n\u001b[32m   2955\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;28;01mand\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m no_val_y:\n\u001b[32m   2956\u001b[39m         out = _check_y(y, **check_params)\n\u001b[32m   2957\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
                        "\u001b[32mc:\\Users\\alsld\\miniconda3\\envs\\DS\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1050\u001b[39m                         )\n\u001b[32m   1051\u001b[39m                     array = xp.astype(array, dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1052\u001b[39m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1053\u001b[39m                     array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n\u001b[32m-> \u001b[39m\u001b[32m1054\u001b[39m             \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[32m   1055\u001b[39m                 raise ValueError(\n\u001b[32m   1056\u001b[39m                     \u001b[33m\"Complex data not supported\\n{}\\n\"\u001b[39m.format(array)\n\u001b[32m   1057\u001b[39m                 ) from complex_warning\n",
                        "\u001b[32mc:\\Users\\alsld\\miniconda3\\envs\\DS\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, dtype, order, copy, xp, device)\u001b[39m\n\u001b[32m    753\u001b[39m         \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[32m    754\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    755\u001b[39m             array = numpy.array(array, order=order, dtype=dtype)\n\u001b[32m    756\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m757\u001b[39m             array = numpy.asarray(array, order=order, dtype=dtype)\n\u001b[32m    758\u001b[39m \n\u001b[32m    759\u001b[39m         \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[32m    760\u001b[39m         \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n",
                        "\u001b[32mc:\\Users\\alsld\\miniconda3\\envs\\DS\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, dtype, copy)\u001b[39m\n\u001b[32m   2167\u001b[39m             )\n\u001b[32m   2168\u001b[39m         values = self._values\n\u001b[32m   2169\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2170\u001b[39m             \u001b[38;5;66;03m# Note: branch avoids `copy=None` for NumPy 1.x support\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2171\u001b[39m             arr = np.asarray(values, dtype=dtype)\n\u001b[32m   2172\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2173\u001b[39m             arr = np.array(values, dtype=dtype, copy=copy)\n\u001b[32m   2174\u001b[39m \n",
                        "\u001b[31mValueError\u001b[39m: could not convert string to float: 'F'"
                    ]
                }
            ],
            "source": [
                "# 4. Encoding, Clustering & Scaling\n",
                "# numerical_feats = train.select_dtypes(exclude='object').columns.tolist()\n",
                "# if 'credit' in numerical_feats: numerical_feats.remove('credit')\n",
                "categorical_feats = train.select_dtypes(include='object').columns.tolist()\n",
                "\n",
                "train['income_total'] = np.log1p(1 + train['income_total'])\n",
                "test['income_total'] = np.log1p(1 + test['income_total'])\n",
                "\n",
                "# encoder = OrdinalEncoder(cols=categorical_feats)\n",
                "# train[categorical_feats] = encoder.fit_transform(train[categorical_feats])\n",
                "# test[categorical_feats] = encoder.transform(test[categorical_feats])\n",
                "\n",
                "# train['ID'] = train['ID'].astype('int64')\n",
                "# test['ID'] = test['ID'].astype('int64')\n",
                "\n",
                "# Clustering\n",
                "kmeans_train = train.drop(['credit'], axis=1)\n",
                "kmeans = KMeans(n_clusters=36, random_state=seed).fit(kmeans_train)\n",
                "train['cluster'] = kmeans.predict(kmeans_train)\n",
                "test['cluster'] = kmeans.predict(test)\n",
                "\n",
                "# Scale other numeric features\n",
                "scale_feats = [f for f in numerical_feats if f != 'income_total']\n",
                "scaler = StandardScaler()\n",
                "train[scale_feats] = scaler.fit_transform(train[scale_feats])\n",
                "test[scale_feats] = scaler.transform(test[scale_feats])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "ename": "CatBoostError",
                    "evalue": "Bad value for num_feature[non_default_doc_idx=0,feature_idx=0]=\"F\": Cannot convert 'F' to float",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
                        "\u001b[36mFile \u001b[39m\u001b[32m_catboost.pyx:2534\u001b[39m, in \u001b[36m_catboost.get_float_feature\u001b[39m\u001b[34m()\u001b[39m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m_catboost.pyx:1228\u001b[39m, in \u001b[36m_catboost._FloatOrNan\u001b[39m\u001b[34m()\u001b[39m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m_catboost.pyx:1023\u001b[39m, in \u001b[36m_catboost._FloatOrNanFromString\u001b[39m\u001b[34m()\u001b[39m\n",
                        "\u001b[31mTypeError\u001b[39m: Cannot convert 'F' to float",
                        "\nDuring handling of the above exception, another exception occurred:\n",
                        "\u001b[31mCatBoostError\u001b[39m                             Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n\u001b[32m     14\u001b[39m y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m train_data = \u001b[43mPool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcat_cols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m valid_data = Pool(data=X_valid, label=y_valid, cat_features=cat_cols)\n\u001b[32m     19\u001b[39m model = CatBoostClassifier(iterations=\u001b[32m2000\u001b[39m, random_seed=seed, early_stopping_rounds=\u001b[32m100\u001b[39m, verbose=\u001b[32m100\u001b[39m)\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alsld\\miniconda3\\envs\\DS\\Lib\\site-packages\\catboost\\core.py:855\u001b[39m, in \u001b[36mPool.__init__\u001b[39m\u001b[34m(self, data, label, cat_features, text_features, embedding_features, embedding_features_data, column_description, pairs, graph, delimiter, has_header, ignore_csv_quoting, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count, log_cout, log_cerr, data_can_be_none)\u001b[39m\n\u001b[32m    849\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(feature_names, PATH_TYPES):\n\u001b[32m    850\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m CatBoostError(\n\u001b[32m    851\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mfeature_names must be None or have non-string type when the pool is created from \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    852\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mpython objects.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    853\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m855\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpairs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    856\u001b[39m \u001b[43m                   \u001b[49m\u001b[43mgroup_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgroup_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpairs_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimestamp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_tags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthread_count\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    857\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data_can_be_none:\n\u001b[32m    858\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CatBoostError(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m'\u001b[39m\u001b[33m parameter can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt be None\u001b[39m\u001b[33m\"\u001b[39m)\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alsld\\miniconda3\\envs\\DS\\Lib\\site-packages\\catboost\\core.py:1491\u001b[39m, in \u001b[36mPool._init\u001b[39m\u001b[34m(self, data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, graph, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count)\u001b[39m\n\u001b[32m   1489\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m feature_tags \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1490\u001b[39m     feature_tags = \u001b[38;5;28mself\u001b[39m._check_transform_tags(feature_tags, feature_names)\n\u001b[32m-> \u001b[39m\u001b[32m1491\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_init_pool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpairs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1492\u001b[39m \u001b[43m                \u001b[49m\u001b[43mgroup_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgroup_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpairs_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimestamp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_tags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthread_count\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m_catboost.pyx:4329\u001b[39m, in \u001b[36m_catboost._PoolBase._init_pool\u001b[39m\u001b[34m()\u001b[39m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m_catboost.pyx:4381\u001b[39m, in \u001b[36m_catboost._PoolBase._init_pool\u001b[39m\u001b[34m()\u001b[39m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m_catboost.pyx:4190\u001b[39m, in \u001b[36m_catboost._PoolBase._init_features_order_layout_pool\u001b[39m\u001b[34m()\u001b[39m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m_catboost.pyx:3114\u001b[39m, in \u001b[36m_catboost._set_features_order_data_pd_data_frame\u001b[39m\u001b[34m()\u001b[39m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m_catboost.pyx:2578\u001b[39m, in \u001b[36m_catboost.create_num_factor_data\u001b[39m\u001b[34m()\u001b[39m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m_catboost.pyx:2536\u001b[39m, in \u001b[36m_catboost.get_float_feature\u001b[39m\u001b[34m()\u001b[39m\n",
                        "\u001b[31mCatBoostError\u001b[39m: Bad value for num_feature[non_default_doc_idx=0,feature_idx=0]=\"F\": Cannot convert 'F' to float"
                    ]
                }
            ],
            "source": [
                "# 5. Modeling\n",
                "n_fold = 15\n",
                "target = 'credit'\n",
                "X = train.drop(target, axis=1)\n",
                "y = train[target]\n",
                "X_test = test\n",
                "\n",
                "skfold = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)\n",
                "cat_pred_test = np.zeros((X_test.shape[0], 3))\n",
                "cat_cols = ['income_type', 'edu_type', 'family_type', 'house_type', 'occyp_type', 'ID']\n",
                "\n",
                "for fold, (train_idx, valid_idx) in enumerate(skfold.split(X, y)):\n",
                "    X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
                "    y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
                "    \n",
                "    train_data = Pool(data=X_train, label=y_train, cat_features=cat_cols)\n",
                "    valid_data = Pool(data=X_valid, label=y_valid, cat_features=cat_cols)\n",
                "    \n",
                "    model = CatBoostClassifier(iterations=2000, random_seed=seed, early_stopping_rounds=100, verbose=100)\n",
                "    model.fit(train_data, eval_set=valid_data, use_best_model=True)\n",
                "    \n",
                "    cat_pred_test += model.predict_proba(X_test) / n_fold\n",
                "    print(f\"Fold {fold} finished.\\n\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "ename": "NameError",
                    "evalue": "name 'cat_pred_test' is not defined",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 6. Submission\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m submission.iloc[:, \u001b[32m1\u001b[39m:] = \u001b[43mcat_pred_test\u001b[49m\n\u001b[32m      3\u001b[39m submission.to_csv(\u001b[33m'\u001b[39m\u001b[33mcombined_submission.csv\u001b[39m\u001b[33m'\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSubmission file \u001b[39m\u001b[33m'\u001b[39m\u001b[33mcombined_submission.csv\u001b[39m\u001b[33m'\u001b[39m\u001b[33m generated successfully!\u001b[39m\u001b[33m\"\u001b[39m)\n",
                        "\u001b[31mNameError\u001b[39m: name 'cat_pred_test' is not defined"
                    ]
                }
            ],
            "source": [
                "# 6. Submission\n",
                "submission.iloc[:, 1:] = cat_pred_test\n",
                "submission.to_csv('combined_submission.csv', index=False)\n",
                "print(\"Submission file 'combined_submission.csv' generated successfully!\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "DS",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
